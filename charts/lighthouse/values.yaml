# Default values for lighthouse.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## Provide a name in place of lighthouse for `app:` labels
##
nameOverride: ""

## Provide a name to substitute for the full names of resources
##
fullnameOverride: ""

## Service account
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
##
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

## Pod Security Context
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
##
securityContext:
  fsGroup: 1001
  runAsUser: 1001

## RBAC configuration.
## ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/
##
rbac:
  ## @param rbac.create Specifies whether RBAC resources are to be created
  ##
  create: true
  ## @param rbac.clusterRules Required ClusterRole rules
  ## @default -- See `values.yaml`
  clusterRules:
    ## Required to obtain the nodes external IP
    - apiGroups: [""]
      resources:
      - "nodes"
      verbs:
      - "get"
      - "list"
      - "watch"
  ## @param rbac.rules Required ClusterRole rules
  ## @default -- See `values.yaml`
  rules:
    ## Required to get information about the serices nodePort.
    - apiGroups: [""]
      resources:
      - "services"
      verbs:
      - "get"
      - "list"
      - "watch"

## Init image is used to chown data volume, initialise genesis, etc.
##
initImage:
  repository: "busybox"
  tag: "1.34"
  pullPolicy: IfNotPresent

## Sidecar image is used to perform Liveness/Readiness probes.
##
sidecar:
  repository: "europe-west4-docker.pkg.dev/stakewiselabs/public/ethnode-sidecar"
  tag: "v1.0.3"
  pullPolicy: IfNotPresent
  bindAddr: "0.0.0.0"
  bindPort: 3000

## Configuration for lighthouse eth v2 beacon chain node
## ref: https://lighthouse-book.sigmaprime.io/
##

## How many beacon chain pods to run simultaneously
##
replicaCount: 1

## Lighthouse beacon node image version
## ref: https://hub.docker.com/r/sigp/lighthouse
image:
  repository: "sigp/lighthouse"
  tag: "v2.3.1"
  pullPolicy: IfNotPresent

## Credentials to fetch images from private registry
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
##
imagePullSecrets: []

## Node labels for pod assignment
## ref: https://kubernetes.io/docs/user-guide/node-selection/
##
nodeSelector: {}

## Tolerations for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: {}

## Affinity for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}

## Used to assign priority to pods
## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/
##
priorityClassName: ""

## Enable pod disruption budget
## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
##
podDisruptionBudget:
  enabled: true
  maxUnavailable: 1

## Vertical Pod Autoscaler config
## ref: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler
##
verticalAutoscaler:
  # If true a VPA object will be created for the StatefulSet
  enabled: false
  updateMode: Off
  containerPolicies: {}

## Eth2 network ID
## Options: mainnet, prater, gnosis
##
network: mainnet

## Rest API Settings
##
http:
  # Enables Beacon Rest API
  enabled: true
  # Port of the REST server
  port: "5052"
  # Port name for the respective k8s service
  portName: "http"
  # Listening address of the REST server
  address: "0.0.0.0"
  # Access-Control-Allow-Origin response HTTP header
  allowOrigin: "*"

## When p2pNodePort is enabled, your P2P port will be exposed via service type NodePort/LoadBalancer.
## This will generate a service for each replica, with a port binding via NodePort/LoadBalancer.
## This is useful if you want to expose and announce your node to the Internet.
##
p2pNodePort:
  ## @param p2pNodePort.enabled Expose P2P port via NodePort
  ##
  enabled: false
  ## @param p2pNodePort.annotations
  ##
  annotations: {}
  ## @param p2pNodePort.type
  ## Options: NodePort, LoadBalancer
  type: NodePort
  ## @param p2pNodePort.startAt The ports allocation will start from this value
  ##
  startAt: 31300
  ## @param p2pNodePort.replicaToNodePort Overwrite a port for specific replicas
  ## @default -- See `values.yaml` for example
  replicaToNodePort: {}
  #  "0": 32345
  #  "3": 32348
  initContainer:
    image:
      ## @param p2pNodePort.initContainer.repository Container image to fetch nodeport information
      ##
      repository: bitnami/kubectl
      ## @param p2pNodePort.initContainer.tag Container tag
      ##
      tag: "1.23"
      ## @param p2pNodePort.initContainer.pullPolicy Container pull policy
      ##
      pullPolicy: IfNotPresent

## The target number of peers.
##
targetPeers: 160

## Extra flags for lighthouse beacon chain node
##
extraFlags:
  - --subscribe-all-subnets
  - --import-all-attestations

## Ethereum 1 node endpoints.
##
eth1Endpoints: []

## Monitoring
##
metrics:
  # Whether to enable metrics collection or not
  enabled: true

  # Prometheus exporter port
  port: 5054

  # Extra flags to pass for collecting metrics
  flags:
    - "--metrics"
    - "--metrics-port=5054"
    - "--metrics-address=0.0.0.0"

  ## Prometheus Service Monitor
  ## ref: https://github.com/coreos/prometheus-operator
  ##      https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
  ##
  serviceMonitor:
    ## @param metrics.serviceMonitor.enabled Create ServiceMonitor resource(s) for scraping metrics using PrometheusOperator
    ##
    enabled: false
    ## @param metrics.serviceMonitor.namespace The namespace in which the ServiceMonitor will be created
    ##
    namespace: ""
    ## @param metrics.serviceMonitor.interval The interval at which metrics should be scraped
    ##
    interval: 30s
    ## @param metrics.serviceMonitor.scrapeTimeout The timeout after which the scrape is ended
    ##
    scrapeTimeout: ""
    ## @param metrics.serviceMonitor.relabellings Metrics RelabelConfigs to apply to samples before scraping.
    ##
    relabellings: []
    ## @param metrics.serviceMonitor.metricRelabelings Metrics RelabelConfigs to apply to samples before ingestion.
    ##
    metricRelabelings: []
    ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint
    ##
    honorLabels: false
    ## @param metrics.serviceMonitor.additionalLabels Additional labels that can be used so ServiceMonitor resource(s) can be discovered by Prometheus
    ##
    additionalLabels: {}
  ## Custom PrometheusRule to be defined
  ## ref: https://github.com/coreos/prometheus-operator#customresourcedefinitions
  ##
  prometheusRule:
    ## @param metrics.prometheusRule.enabled Create a custom prometheusRule Resource for scraping metrics using PrometheusOperator
    ##
    enabled: false
    ## @param metrics.prometheusRule.default Create a default set of Alerts
    ##
    default: true
    ## @param metrics.prometheusRule.namespace The namespace in which the prometheusRule will be created
    ##
    namespace: ""
    ## @param metrics.prometheusRule.additionalLabels Additional labels for the prometheusRule
    ##
    additionalLabels: {}
    ## @param metrics.prometheusRule.rules Custom Prometheus rules
    ##
    rules: []

## Defines whether the service must be headless
##
svcHeadless: false

## Configure session affinity for validator clients to hit the same beacon node
## for the period specified in `timeoutSeconds`
## ref: https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-userspace
##
sessionAffinity:
  # Whether to enable session affinity or not
  enabled: true
  # The session duration in seconds
  timeoutSeconds: 86400

## Configure resource requests and limits.
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources: {}

## Configure liveness and readiness probes
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
##
livenessProbe:
  enabled: true
  initialDelaySeconds: 900
  timeoutSeconds: 3
  periodSeconds: 30
  failureThreshold: 3
  successThreshold: 1
  httpGet:
    path: /eth2/liveness
    port: sidecar
    scheme: HTTP

readinessProbe:
  enabled: true
  initialDelaySeconds: 300
  timeoutSeconds: 3
  periodSeconds: 30
  failureThreshold: 30
  successThreshold: 2
  httpGet:
    path: /eth2/readiness
    port: sidecar
    scheme: HTTP

## If false, data ownership will not be reset at startup
## This allows the geth node to be run with an arbitrary user
##
initChownData: true

## Whether or not to allocate persistent volume disk for the data directory.
## In case of pod failure, the pod data directory will still persist.
##
persistence:
  enabled: true
  storageClassName: ""
  accessModes:
    - ReadWriteOnce
  size: 250Gi
  annotations: {}
