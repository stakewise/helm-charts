# Default values for openethereum.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# general configuration options for the openethereum instance
openethereum:
  # which network should the node join
  chain: mainnet
  # chain-dependend configurations
  chains:
    # configurations values for the mainnet chain
    mainnet:
    # configurations values for the ropsten chain
    ropsten:
    # configurations values for the goerli chain
    goerli:
      # known available boot nodes (fetched from https://github.com/goerli/testnet/blob/master/bootnodes.txt)
      bootnodes:
        - "enode://011f758e6552d105183b1761c5e2dea0111bc20fd5f6422bc7f91e0fabbec9a6595caf6239b37feb773dddd3f87240d99d859431891e4a642cf2a0a9e6cbb98a@51.141.78.53:30303"
        - "enode://176b9417f511d05b6b2cf3e34b756cf0a7096b3094572a8f6ef4cdcb9d1f9d00683bf0f83347eebdf3b81c3521c2332086d9592802230bf528eaf606a1d9677b@13.93.54.137:30303"
        - "enode://46add44b9f13965f7b9875ac6b85f016f341012d84f975377573800a863526f4da19ae2c620ec73d11591fa9510e992ecc03ad0751f53cc02f7c7ed6d55c7291@94.237.54.114:30313"
        - "enode://b5948a2d3e9d486c4d75bf32713221c2bd6cf86463302339299bd227dc2e276cd5a1c7ca4f43a0e9122fe9af884efed563bd2a1fd28661f3b5f5ad7bf1de5949@18.218.250.66:30303"
  # Extra flags to pass to the open ethereum node
  extraFlags: []

  metrics:
    # Whether to enable metrics collection or not
    enabled: false
    port: 3000
  
    ## Prometheus Service Monitor
    ## ref: https://github.com/coreos/prometheus-operator
    ##      https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    serviceMonitor:
      ## @param metrics.serviceMonitor.enabled Create ServiceMonitor resource(s) for scraping metrics using PrometheusOperator
      ##
      enabled: false
      ## @param metrics.serviceMonitor.namespace The namespace in which the ServiceMonitor will be created
      ##
      namespace: ""
      ## @param metrics.serviceMonitor.interval The interval at which metrics should be scraped
      ##
      interval: 30s
      ## @param metrics.serviceMonitor.scrapeTimeout The timeout after which the scrape is ended
      ##
      scrapeTimeout: ""
      ## @param metrics.serviceMonitor.relabellings Metrics RelabelConfigs to apply to samples before scraping.
      ##
      relabellings: []
      ## @param metrics.serviceMonitor.metricRelabelings Metrics RelabelConfigs to apply to samples before ingestion.
      ##
      metricRelabelings: []
      ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint
      ##
      honorLabels: false
      ## @param metrics.serviceMonitor.additionalLabels Additional labels that can be used so ServiceMonitor resource(s) can be discovered by Prometheus
      ##
      additionalLabels: {}
    ## Custom PrometheusRule to be defined
    ## ref: https://github.com/coreos/prometheus-operator#customresourcedefinitions
    ##
    prometheusRule:
      ## @param metrics.prometheusRule.enabled Create a custom prometheusRule Resource for scraping metrics using PrometheusOperator
      ##
      enabled: false
      ## @param metrics.prometheusRule.namespace The namespace in which the prometheusRule will be created
      ##
      namespace: ""
      ## @param metrics.prometheusRule.additionalLabels Additional labels for the prometheusRule
      ##
      additionalLabels: {}
      ## @param metrics.prometheusRule.rules Custom Prometheus rules
      ## e.g:
      ## rules:
      ##   - alert: OpenEthereumSnapshotOufOfSync
      ##     expr: snapshot_download_chunks_done{service="{{ include "openethereum.fullname" . }}"} < snapshot_download_chunks{service="{{ template "openethereum.fullname" . }}"}
      ##     for: 30m
      ##     labels:
      ##       severity: error
      ##     annotations:
      ##       summary: Snapshot state is out of sync
      ##       description: Check OpenEthereum Node
      ##
      rules: []

replicaCount: 1

image:
  repository: openethereum/openethereum
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "v3.2.6"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

# Init image is used to chown data volume, initialise genesis, etc.
initImage:
  repository: "busybox"
  tag: "1.34"
  pullPolicy: IfNotPresent

# If false, data ownership will not be reset at startup
# This allows the geth node to be run with an arbitrary user
initChownData: true

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

securityContext:
  fsGroup: 1001
  runAsUser: 1001

services:
  - name: rpc
    port: 8545
    protocol: TCP
  - name: ws
    port: 8546
    protocol: TCP

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
          port: 8545
        - path: /ws
          pathType: ImplementationSpecific
          port: 8546
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  type: pvc
  enabled: false
  # storageClassName: default
  accessModes:
    - ReadWriteOnce
  size: 350Gi
  # annotations: {}
  finalizers:
    - kubernetes.io/pvc-protection
  # selectorLabels: {}
  # subPath: ""
  # existingClaim:

nodeSelector: {}

tolerations: []

affinity: {}
