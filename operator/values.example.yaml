## This is testing configuration file
## Needed to test operator helm chart on test network
##

## Geth node configuration
##
geth:
  enabled: true
  replicas: 1
  extraFlags:
    - "--syncmode=snap"
    - "--goerli"
  nodeSelector:
    cloud.google.com/gke-preemptible: "true"
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
    prometheusRule:
      enabled: false

## Openethereum node configuration
##
openethereum:
  enabled: true
  replicas: 1
  chain: goerli
  extraFlags:
    - " --pruning-memory"
    - "1024"
    - "--no-warp"
    - "--pruning"
    - "fast"
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
    prometheusRule:
      enabled: false
  nodeSelector:
    cloud.google.com/gke-preemptible: "true"
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: component
              operator: In
              values:
              - lighthouse-beacon
          topologyKey: kubernetes.io/hostname

## Prysm beacon chain node configuration
##
prysm:
  enabled: true
  nodeSelector:
    cloud.google.com/gke-preemptible: "true"
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: component
              operator: In
              values:
              - lighthouse-beacon
          topologyKey: kubernetes.io/hostname
  replicas: 1
  networkID: prater
  extraFlags:
    # Beacon chain options
    - "--accept-terms-of-use"
    - "--http-web3provider=http://operator-geth:8545"
    - "--fallback-web3provider=http://operator-openethereum:8545"
    # p2p options
    - "--p2p-max-peers=100"
    - "--enable-peer-scorer"
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
    prometheusRule:
      enabled: false
  persistence:
    enabled: true
    storageClassName: "ssd-storage"
    accessModes:
      - ReadWriteOnce
    size: 300Gi

## Lighthouse beacon chain node configuration
##
lighthouse:
  enabled: true
  replicas: 1
  networkID: prater
  eth1Endpoints:
    - http://operator-geth:8545
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
    prometheusRule:
      enabled: false
  persistence:
    enabled: true
    storageClassName: "ssd-storage"
    accessModes:
      - ReadWriteOnce
    size: 300Gi
  nodeSelector:
    cloud.google.com/gke-preemptible: "true"

## Validators configuration
##
validator:
  enabled: true
  verticalAutoscaler:
    enabled: true
  validatorsCount: 1
  type: prysm
  graffiti: "StakeWise"
  publicKey: ""
  networkID: "prater"
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
    prometheusRule:
      enabled: false
  persistence:
    enabled: true
    storageClassName: "standard"
    accessModes:
      - ReadWriteOnce
    size: 10Gi

## Hashicorp Vault configurations
##
vault:
  enabled: true
  server:
    enabled: true
    dataStorage:
      enabled: true
      storageClass: "ssd-storage"
      accessMode: ReadWriteOnce
      size: 10Gi
    ha:
      enabled: true
      replicas: 3
      raft:
        enabled: true
        # Note: Configuration files are stored in ConfigMaps so sensitive data
        # such as passwords should be either mounted through extraSecretEnvironmentVars
        # or through a Kube secret.  For more information see:
        # https://www.vaultproject.io/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations
        config: |
          ui = true
          listener "tcp" {
            tls_disable = 1
            address = "[::]:8200"
            cluster_address = "[::]:8201"
          }
          storage "raft" {
            path = "/vault/data"
          }
          service_registration "kubernetes" {}
          seal "gcpckms" {
             project     = "stakewise-staging"
             region      = "global"
             key_ring    = "operator"
             crypto_key  = "vault"
          }
    extraEnvironmentVars:
      GOOGLE_REGION: global
      GOOGLE_PROJECT: stakewise-staging
      GOOGLE_APPLICATION_CREDENTIALS: /vault/userconfig/stakewise/gcp-creds.json

    # volumes is a list of volumes made available to all containers. These are rendered
    # via toYaml rather than pre-processed like the extraVolumes value.
    # The purpose is to make it easy to share volumes between containers.
    volumes:
      - name: gcp-creds
        secret:
          secretName: gcp-creds
          items:
            - key: gcp-creds.json
              path: gcp-creds.json

    # volumeMounts is a list of volumeMounts for the main server container. These are rendered
    # via toYaml rather than pre-processed like the extraVolumes value.
    # The purpose is to make it easy to share volumes between containers.
    volumeMounts:
      - name: gcp-creds
        mountPath: "/vault/userconfig/stakewise/gcp-creds.json"
        subPath: gcp-creds.json
        readOnly: true
   
  ui:
    enabled: true
